{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastText ile yazım denetimi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu çalışmada fastText ile basit bir yazım denetimi uygulaması deniyorum.\n",
    "\n",
    "FastText, her bir kelimenin, kelimenin kendisine ek olarak n-gramlık bir karakter çantası olarak temsil edilebileceği şekilde alt kelime temsillerini destekler.\n",
    "\n",
    "FastText kelime vektörlerine dayalı bir yazım denetleyici uygulaması oluşturmaya çalışacağı. Yanlış yazılmış bir kelime verildiğinde eğitimli gömme uzayında bu kelimenin vektör temsiline en yakın kelime vektör temsilini bulmak olacaktır.\n",
    "\n",
    "Eğer kelime hazinemizde aranılan kelime yer alıyorsa kelimeyi olduğu haliyle bırakacağız, aksi durumda  alt kelime temsillerine en yakın olan ile değiştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None);\n",
    "pd.set_option(\"display.max_rows\",None);\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text_nobracket = re.sub(\".*?\\((.*?)\\)\", '', str(text.lower()))\n",
    "    text_nopunct = re.sub(r'[^\\w\\s]','', str(text_nobracket))\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "WPT = nltk.WordPunctTokenizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = WPT.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def tokenize_sent(text):\n",
    "    tokens = sent_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'hopi.com.tr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://hopi.com.tr/markalar' , verify=False)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'style', 'header', 'nav', 'ul', 'h2', 'h5', 'noscript', 'a', 'div', 'section', 'h1', 'label', 'li', 'p', '[document]', 'span', 'title', 'body', 'h6', 'form', 'strong', 'html', 'svg', 'button', 'main', 'head', 'figure', 'footer', 'script'}\n"
     ]
    }
   ],
   "source": [
    "print(set([text.parent.name for text in soup.find_all(text=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopi = []\n",
    "for brand in soup.find_all(\"span\", {\"class\" : \"title\"}):\n",
    "    hopi.append(brand.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01 BURDA AVM', '49.COM.TR', 'A101', 'ABDULLAH KİĞILI', 'AGORA ANTALYA AVM']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopi[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORHIPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.morhipo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://www.morhipo.com/markalar/0/marka' , verify=False)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'style', 'header', 'ul', 'ol', 'noscript', 'a', 'div', 'b', 'h1', 'li', 'p', '[document]', 'span', 'title', 'body', 'strong', 'html', 'button', 'main', 'head', 'footer', 'script'}\n"
     ]
    }
   ],
   "source": [
    "print(set([text.parent.name for text in soup.find_all(text=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "morhipo = []\n",
    "for li in soup.find_all(class_= \"chaar-item col-xxs-12 col-xs-6 col-sm-3\"):\n",
    "    morhipo.append(li.a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/a-m-eyewear', '/a-spor', '/abottega', '/agspalding-bros', '/akent']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morhipo[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRM_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_list = list(set(morhipo) - set(hopi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "firmname = pd.DataFrame(firm_list, columns = [\"FIRMNAME\"])\n",
    "firmname.FIRMNAME = [re.sub(\"/\", '', str(x).lower()) for x in firmname.FIRMNAME]\n",
    "firmname.FIRMNAME = [re.sub(\"-\", ' ', str(x)) for x in firmname.FIRMNAME]\n",
    "firmname[\"FIRMNAME2\"] = [re.sub(\" \", '', str(x)) for x in firmname.FIRMNAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "firmname.loc[:,'FIRMNAME'] = firmname.loc[:,'FIRMNAME'].apply(lambda x: cleaning_text(x))\n",
    "firmname.loc[:,'Sent_Token1'] = firmname.loc[:,'FIRMNAME'].apply(lambda x: tokenize_sent(x) )\n",
    "\n",
    "firmname.loc[:,'FIRMNAME2'] = firmname.loc[:,'FIRMNAME2'].apply(lambda x: cleaning_text(x))\n",
    "firmname.loc[:,'Sent_Token2'] = firmname.loc[:,'FIRMNAME2'].apply(lambda x: tokenize_sent(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRMNAME</th>\n",
       "      <th>FIRMNAME2</th>\n",
       "      <th>Sent_Token1</th>\n",
       "      <th>Sent_Token2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exuma</td>\n",
       "      <td>exuma</td>\n",
       "      <td>[exuma]</td>\n",
       "      <td>[exuma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joygears</td>\n",
       "      <td>joygears</td>\n",
       "      <td>[joygears]</td>\n",
       "      <td>[joygears]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>redoxon</td>\n",
       "      <td>redoxon</td>\n",
       "      <td>[redoxon]</td>\n",
       "      <td>[redoxon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baby londy</td>\n",
       "      <td>babylondy</td>\n",
       "      <td>[baby londy]</td>\n",
       "      <td>[babylondy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>densmood</td>\n",
       "      <td>densmood</td>\n",
       "      <td>[densmood]</td>\n",
       "      <td>[densmood]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FIRMNAME  FIRMNAME2   Sent_Token1  Sent_Token2\n",
       "0       exuma      exuma       [exuma]      [exuma]\n",
       "1    joygears   joygears    [joygears]   [joygears]\n",
       "2     redoxon    redoxon     [redoxon]    [redoxon]\n",
       "3  baby londy  babylondy  [baby londy]  [babylondy]\n",
       "4    densmood   densmood    [densmood]   [densmood]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firmname.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list =  firmname[\"Sent_Token1\"].tolist() + firmname[\"Sent_Token2\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastText Spell Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(178700, 178700)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext = FastText(brand_list, vector_size=400, window=7, min_count =1,  min_n=3, max_n=6)\n",
    "%time cbow_fasttext.train(brand_list,total_examples=len(brand_list), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_words = [(\"sennhayser\" ),\n",
    "(\"senheiser\"),\n",
    "(\"sennheiser\"),\n",
    "(\"diyiturk\" ),\n",
    "(\"lc waykiki\"),\n",
    "(\"sennhayser\" ),\n",
    "(\"dokers\"),\n",
    "(\"digitürk\"),\n",
    "( \"lc waykiki\"),\n",
    "(\"dikiturk\"),\n",
    "(\"vestl\"),\n",
    "(\"rusel hobs\"),\n",
    "(\"russell hobbs\")]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested word for sennhayser : sennheiser\n",
      "Suggested word for senheiser : sennheiser\n",
      "sennheiser exists in the vocabulary. No correction required\n",
      "Suggested word for diyiturk : digiturk\n",
      "Suggested word for lc waykiki : lc waikiki\n",
      "Suggested word for sennhayser : sennheiser\n",
      "Suggested word for dokers : dockers\n",
      "Suggested word for digitürk : digiturk\n",
      "Suggested word for lc waykiki : lc waikiki\n",
      "Suggested word for dikiturk : digiturk\n",
      "Suggested word for vestl : vestel\n",
      "Suggested word for rusel hobs : russell hobbs\n",
      "russell hobbs exists in the vocabulary. No correction required\n"
     ]
    }
   ],
   "source": [
    "def spellcheck(tests, model, vocab):\n",
    "    for wrong in wrong_words:\n",
    "        w = wrong\n",
    "        if w in vocab:\n",
    "            print('{} exists in the vocabulary. No correction required'.format(w))\n",
    "        else:\n",
    "            w_old = w\n",
    "            w = cbow_fasttext.wv.most_similar_to_given(w, list(vocab))\n",
    "            print(\"Suggested word for {} : {}\".format(w_old, w))\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    model = cbow_fasttext\n",
    "    vocab = cbow_fasttext.wv.key_to_index.keys()\n",
    "    spellcheck(wrong_words, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sennheiser'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"sennhayser\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lc waikiki'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"lc waykiki\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcwaikiki'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"lcwaykiki\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digiturk'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"diyiturk\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digiturk'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"dikiturk\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dockers'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"dokers\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vestel'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"vestl\", list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'russell hobbs'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fasttext.wv.most_similar_to_given(\"rusel hobs\", list(vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
